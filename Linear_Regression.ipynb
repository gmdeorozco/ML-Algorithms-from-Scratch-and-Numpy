{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOm2QG8xNbHa+ZxHu7qx1oe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmdeorozco/ML-Algorithms-from-Scratch-and-Numpy/blob/main/Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Linear Regression using the Pseudo Inverse Method\n",
        "\n",
        "In this Jupyter notebook, we will explore Linear Regression, one of the simplest yet powerful Machine Learning algorithms used for predicting numeric values. We will specifically focus on the implementation of Linear Regression using the Pseudo Inverse method.\n",
        "\n",
        "### The Code\n",
        "\n",
        "The core of our implementation is the `LinearRegression` class. Let's briefly go through the key steps involved:\n",
        "\n",
        "1. **Initialization**: We start by defining the `LinearRegression` class. The `__init__` method initializes the `coef_` attribute, which will store the coefficients of our linear regression model.\n",
        "\n",
        "2. **Fitting the Model**: The `fit` method is used to train the linear regression model. First, we insert a column of ones in the feature matrix `X`, which is necessary for the intercept term in our linear equation. Then, we perform matrix operations to calculate the optimal coefficients using the Pseudo Inverse method.\n",
        "\n",
        "3. **Pseudo Inverse Method**: The Pseudo Inverse method is an alternative to the Ordinary Least Squares (OLS) method, and it enables us to find the solution for the linear regression coefficients without directly inverting a possibly singular matrix. We calculate the pseudo-inverse of the product of the transpose of `X` and `X`, and then use it to find the coefficients.\n",
        "\n",
        "4. **Prediction**: The `predict` method allows us to make predictions using the trained linear regression model. Similar to the `fit` method, we insert a column of ones in the feature matrix `X` for the intercept term, and then obtain the predicted values by multiplying the feature matrix with the trained coefficients.\n",
        "\n",
        "5. **Data and Prediction Example**: We create a linear regression object `regressor` and generate some dummy data for demonstration purposes. We fit the model to the data and then make predictions on a test feature matrix `X_test`.\n",
        "\n",
        "### What You'll Learn\n",
        "\n",
        "By going through this notebook, you'll gain a better understanding of how Linear Regression works, the mathematics behind the Pseudo Inverse method, and how to implement it using Python and NumPy. This notebook serves as a foundational step to explore more complex Machine Learning algorithms and their practical applications.\n",
        "\n",
        "Now, let's dive into the code and witness Linear Regression in action!"
      ],
      "metadata": {
        "id": "wm6bMmDGTWnT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOoYAirU3-0Y",
        "outputId": "c3cf6889-aa74-4018-f3b3-bc1b008bc43e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [[ 53.]\n",
            " [124.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class LinearRegression:\n",
        "    def __init__(self):\n",
        "        self.coef_ = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "      X = np.insert(X, 0, 1, axis=1)  # Insert a column of ones for the intercept term\n",
        "      X_transpose_X = X.T @ X\n",
        "      pseudo_inverse = np.linalg.pinv(X_transpose_X)\n",
        "      self.coef_ = pseudo_inverse @ X.T @ y\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.insert(X, 0, 1, axis=1)  # Insert a column of ones for the intercept term\n",
        "        return X @ self.coef_\n",
        "\n",
        "# Create a linear regression object\n",
        "regressor = LinearRegression()\n",
        "\n",
        "# Generate some dummy data\n",
        "X = np.array([\n",
        "     [ 2.0,5.0],\n",
        "     [4.0,6.0],\n",
        "     [10.0,8.0],\n",
        "     [9.0,2.0],\n",
        "     [8.0,2.0]\n",
        "  ]) # Feature matrix\n",
        "\n",
        "y = np.array([[53],\n",
        "              [76],\n",
        "              [140],\n",
        "              [101],\n",
        "              [92]\n",
        "              ])  # Target vector\n",
        "\n",
        "# Fit the linear regression model\n",
        "regressor.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "X_test = np.array([[2, 5], [6, 12]])  # Test feature matrix\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "print(\"Predictions:\", y_pred)\n"
      ]
    }
  ]
}